{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped ./camera_cal\\calibration1.jpg\n",
      "Appended corners from ./camera_cal\\calibration10.jpg\n",
      "Appended corners from ./camera_cal\\calibration11.jpg\n",
      "Appended corners from ./camera_cal\\calibration12.jpg\n",
      "Appended corners from ./camera_cal\\calibration13.jpg\n",
      "Appended corners from ./camera_cal\\calibration14.jpg\n",
      "Appended corners from ./camera_cal\\calibration15.jpg\n",
      "Appended corners from ./camera_cal\\calibration16.jpg\n",
      "Appended corners from ./camera_cal\\calibration17.jpg\n",
      "Appended corners from ./camera_cal\\calibration18.jpg\n",
      "Appended corners from ./camera_cal\\calibration19.jpg\n",
      "Appended corners from ./camera_cal\\calibration2.jpg\n",
      "Appended corners from ./camera_cal\\calibration20.jpg\n",
      "Appended corners from ./camera_cal\\calibration3.jpg\n",
      "Skipped ./camera_cal\\calibration4.jpg\n",
      "Skipped ./camera_cal\\calibration5.jpg\n",
      "Appended corners from ./camera_cal\\calibration6.jpg\n",
      "Appended corners from ./camera_cal\\calibration7.jpg\n",
      "Appended corners from ./camera_cal\\calibration8.jpg\n",
      "Appended corners from ./camera_cal\\calibration9.jpg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "%matplotlib qt\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "nx = 9\n",
    "ny = 6\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        print('Appended corners from ' + fname)\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(500)\n",
    "    else:\n",
    "        print('Skipped ' + fname)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def CalSingle(img, save = False):\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        if save:\n",
    "            cv2.imwrite('output_images\\\\corners.jpg', img)\n",
    "        cv2.imshow('img', img)\n",
    "    else:\n",
    "        print('Skipped ')\n",
    "    return\n",
    "\n",
    "# Test Function\n",
    "CalSingle(cv2.imread(images[11]), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute camera matrix and correct distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def undistort(img, mtx, dist, save = False):\n",
    "    # Use cv2.undistort()\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    if save:\n",
    "        cv2.imwrite('output_images\\\\undist.jpg', undist)\n",
    "    return undist\n",
    "\n",
    "# Test Function\n",
    "\n",
    "undistorted = undistort(cv2.imread(images[11]), mtx, dist, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 1280, y = 720\n",
      "[[[ 750  446]\n",
      "  [ 530  446]\n",
      "  [  90  663]\n",
      "  [1190  663]]]\n"
     ]
    }
   ],
   "source": [
    "a = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "plt.imshow(a)\n",
    "#src = np.float32([[567,446],[706,446],[133,663],[1171,663]])\n",
    "#dst = np.float32([[100,100],[1200,100],[100,900],[1200,900]])x = int(a.shape[1])\n",
    "x = int(a.shape[1])\n",
    "y = int(a.shape[0])\n",
    "src = np.float32([[x/2-70,446],[x/2+70,446],[x/2-550,650],[x/2+550,650]])\n",
    "dst = np.float32([[100,0],[1200,0],[100,700],[1200,700]])\n",
    "print('x = {}, y = {}'.format(x,y))\n",
    "poly = np.array([[(750,446),(530,446),(90,663),(1190,663)]])\n",
    "print(poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Sobel thresholding in x or y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', thresh_min=0, thresh_max=255, convert = True):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    if convert:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = img\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    if orient == 'y':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "    sbinary = np.zeros_like(scaled_sobel)\n",
    "    # is > thresh_min and < thresh_max\n",
    "    sbinary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return sbinary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Magnitude of the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0,ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1,ksize=sobel_kernel)\n",
    "    # 3) Calculate the magnitude \n",
    "    abs_sobel = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    sbinary = np.zeros_like(scaled_sobel)\n",
    "    sbinary[(scaled_sobel >= mag_thresh[0]) & (scaled_sobel <= mag_thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return sbinary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direction of the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    sobelx = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0,ksize=sobel_kernel))\n",
    "    sobely = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1,ksize=sobel_kernel))\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient\n",
    "    abs_sobel = np.sqrt(sobelx**2 + sobely**2)\n",
    "    dir_sobel = np.arctan2(sobely, sobelx)\n",
    "    scaled_abs_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    sbinary = np.zeros_like(dir_sobel)\n",
    "    sbinary[(dir_sobel >= thresh[0]) & (dir_sobel <= thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return sbinary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HLS select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hls_select(img, thresh=(0, 255)):\n",
    "    # 1) Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    test = hls[:,:,2]\n",
    "    # 2) Apply a threshold to the S channel\n",
    "    binary_output = np.zeros_like(test)\n",
    "    binary_output[(test > thresh[0]) & (test <= thresh[1])] = 1\n",
    "    # 3) Return a binary image of threshold result\n",
    "    return binary_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "def corners_unwarp(img, M = M): \n",
    "    \n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = os.listdir(\"test_images/\")\n",
    "\n",
    "def pipeline(image_name, write_out = False):\n",
    "    \n",
    "    if write_out:\n",
    "        image = mpimg.imread(\"test_images/\" + image_name)\n",
    "    else:\n",
    "        image = image_name\n",
    "        \n",
    "    img_original = np.copy(image)\n",
    "    \n",
    "    undist = undistort(image, mtx, dist)\n",
    "    masked = region_of_interest(image, poly)\n",
    "    sobel_x = abs_sobel_thresh(masked, orient='x', thresh_min=50, thresh_max=255)\n",
    "    sobel_mag = mag_thresh(masked, sobel_kernel=3, mag_thresh=(30, 100))\n",
    "    sobel_dir = dir_threshold(masked, sobel_kernel=15, thresh=(0.8, 1.2))\n",
    "    hls_s = abs_sobel_thresh(hls_select(masked, thresh=(90, 255)), orient='x', thresh_min=50, thresh_max=255, convert = False)\n",
    "    \n",
    "    #test = np.zeros_like(sobel_x)+ 255\n",
    "    #test = np.dstack((test,test,test))\n",
    "    # color binary\n",
    "    #color_binary = np.zeros_like(sobel_x)\n",
    "    sobel_binary = np.dstack(( sobel_x, sobel_mag, sobel_dir ))\n",
    "\n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(sobel_x)\n",
    "    combined_binary[(sobel_x == 1) | (hls_s == 1)] = 1 # (sobel_mag == 1) & (sobel_dir == 1)\n",
    "\n",
    "    # Plotting thresholded images\n",
    "    f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(20,10))\n",
    "    ax1.set_title('Stacked sobel thresholds')\n",
    "    ax1.imshow(corners_unwarp(sobel_binary))\n",
    "    \n",
    "    ax2.set_title('HLS S channel threshold')\n",
    "    ax2.imshow(corners_unwarp(hls_s))\n",
    "\n",
    "    ax3.set_title('Combined S channel and gradient thresholds')\n",
    "    ax3.imshow(corners_unwarp(combined_binary), cmap='gray')\n",
    "    \n",
    "    ax4.set_title('Original')\n",
    "    ax4.imshow(corners_unwarp(img_original))\n",
    "    \n",
    "    # Save images\n",
    "    if write_out:\n",
    "        cv2.imwrite(os.path.join('output_images',image_name + '_binary'), combined_binary*255)\n",
    "        pass\n",
    "    return\n",
    "\n",
    "[pipeline(x,True) for x in test_list];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "def process_image(image):\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    # TODO: put your pipeline here,\n",
    "    # you should return the final output (image where lines are drawn on lanes)\n",
    "    result = pipeline(image)\n",
    "\n",
    "    return result\n",
    "\n",
    "first_video = 'project_video_out.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip('project_video.mp4').subclip(0,5)\n",
    "clip1 = VideoFileClip('project_video.mp4')\n",
    "first_video = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "\n",
    "%time white_clip.write_videofile(first_video, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
